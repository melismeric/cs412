{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GyjD3s_r0Dr_",
    "outputId": "3c38e430-001a-4cdb-c103-09a41479c6ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 59)"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "trainData = pd.read_csv(\"loansTrain.csv\")\n",
    "testData = pd.read_csv(\"loansTest.csv\")\n",
    "trainData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sJTaTemkb6y"
   },
   "source": [
    "**TRAINING SET PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "CN4NGA6zJNOc",
    "outputId": "3ebb9c1b-c1a4-49ac-fcdb-28fdd3f2f527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['emp_length', 'earliest_cr_line', 'grade_A', 'grade_B', 'grade_C',\n",
      "       'grade_D', 'grade_E', 'grade_F', 'grade_G', 'home_ownership_ANY',\n",
      "       'home_ownership_MORTGAGE', 'home_ownership_NONE',\n",
      "       'home_ownership_OTHER', 'home_ownership_OWN', 'home_ownership_RENT',\n",
      "       'verification_status_Not Verified',\n",
      "       'verification_status_Source Verified', 'verification_status_Verified',\n",
      "       'purpose_car', 'purpose_credit_card', 'purpose_debt_consolidation',\n",
      "       'purpose_educational', 'purpose_home_improvement', 'purpose_house',\n",
      "       'purpose_major_purchase', 'purpose_medical', 'purpose_moving',\n",
      "       'purpose_other', 'purpose_renewable_energy', 'purpose_small_business',\n",
      "       'purpose_vacation', 'purpose_wedding', 'addr_state_AK', 'addr_state_AL',\n",
      "       'addr_state_AR', 'addr_state_AZ', 'addr_state_CA', 'addr_state_CO',\n",
      "       'addr_state_CT', 'addr_state_DC', 'addr_state_DE', 'addr_state_FL',\n",
      "       'addr_state_GA', 'addr_state_HI', 'addr_state_IA', 'addr_state_ID',\n",
      "       'addr_state_IL', 'addr_state_IN', 'addr_state_KS', 'addr_state_KY',\n",
      "       'addr_state_LA', 'addr_state_MA', 'addr_state_MD', 'addr_state_ME',\n",
      "       'addr_state_MI', 'addr_state_MN', 'addr_state_MO', 'addr_state_MS',\n",
      "       'addr_state_MT', 'addr_state_NC', 'addr_state_ND', 'addr_state_NE',\n",
      "       'addr_state_NH', 'addr_state_NJ', 'addr_state_NM', 'addr_state_NV',\n",
      "       'addr_state_NY', 'addr_state_OH', 'addr_state_OK', 'addr_state_OR',\n",
      "       'addr_state_PA', 'addr_state_RI', 'addr_state_SC', 'addr_state_SD',\n",
      "       'addr_state_TN', 'addr_state_TX', 'addr_state_UT', 'addr_state_VA',\n",
      "       'addr_state_VT', 'addr_state_WA', 'addr_state_WI', 'addr_state_WV',\n",
      "       'addr_state_WY'],\n",
      "      dtype='object')\n",
      "Index(['loan_amnt', 'revol_bal', 'application_type', 'term', 'grade_A',\n",
      "       'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F',\n",
      "       ...\n",
      "       'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq',\n",
      "       'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens',\n",
      "       'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_il_high_credit_limit',\n",
      "       'loan_status'],\n",
      "      dtype='object', length=131)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numvars_2 = ['loan_amnt','revol_bal']\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numerical_columns = pd.DataFrame(StandardScaler().fit_transform(trainData[numvars_2]),columns = numvars_2)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#Binary\n",
    "trainData['application_type'] = pd.to_numeric(trainData['application_type'], errors='coerce')\n",
    "trainData['emp_length'] = pd.to_numeric(trainData['emp_length'], errors='coerce')\n",
    "trainData['earliest_cr_line'] = pd.to_numeric(trainData['earliest_cr_line'], errors='coerce')\n",
    "LE = LabelEncoder()\n",
    "trainData['application_type'] = LE.fit_transform(trainData['application_type'])\n",
    "trainData['term'] = LE.fit_transform(trainData['term'].astype(str))\n",
    "\n",
    "\n",
    "\n",
    "#categorical variables labels\n",
    "\n",
    "categorical = ['grade', 'emp_length','home_ownership','verification_status', 'purpose', 'addr_state', 'earliest_cr_line']\n",
    "dummy_df = pd.get_dummies(trainData[categorical])\n",
    "print(dummy_df.columns)\n",
    "\n",
    "\n",
    "trainData1 = trainData.drop('application_type',axis=1)\n",
    "trainData1 = trainData1.drop('term',axis=1)\n",
    "trainData1 = trainData1.drop(categorical, axis=1)\n",
    "trainData1 = trainData1.drop('zip_code', axis = 1)\n",
    "trainData1 = trainData1.drop('emp_title', axis=1)\n",
    "trainData1 = trainData1.drop(numvars_2, axis = 1)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(trainData1)\n",
    "trainData1 = df.loc[:, df.isnull().mean() < .8]\n",
    "\n",
    "\n",
    "\n",
    "trainData1['tot_coll_amt'].fillna((trainData1['tot_coll_amt'].mean()), inplace=True)\n",
    "trainData1['tot_cur_bal'].fillna((trainData1['tot_cur_bal'].mean()), inplace=True)\n",
    "trainData1['total_rev_hi_lim'].fillna((trainData1['total_rev_hi_lim'].mean()), inplace=True)\n",
    "trainData1['num_accts_ever_120_pd'].fillna((trainData1['num_accts_ever_120_pd'].mean()), inplace=True)\n",
    "trainData1['dti'].fillna((trainData1['dti'].mean()), inplace=True)\n",
    "trainData1['delinq_2yrs'].fillna((trainData1['delinq_2yrs'].mean()), inplace=True)\n",
    "trainData1['num_actv_bc_tl'].fillna((trainData1['num_actv_bc_tl'].mean()), inplace=True)\n",
    "trainData1['num_actv_rev_tl'].fillna((trainData1['num_actv_rev_tl'].mean()), inplace=True)\n",
    "trainData1['num_bc_sats'].fillna((trainData1['num_bc_sats'].mean()), inplace=True)\n",
    "trainData1['num_bc_tl'].fillna((trainData1['num_bc_tl'].mean()), inplace=True)\n",
    "trainData1['num_il_tl'].fillna((trainData1['num_il_tl'].mean()), inplace=True)\n",
    "trainData1['num_op_rev_tl'].fillna((trainData1['num_op_rev_tl'].mean()), inplace=True)\n",
    "trainData1['num_rev_accts'].fillna((trainData1['num_rev_accts'].mean()), inplace=True)\n",
    "trainData1['num_rev_tl_bal_gt_0'].fillna((trainData1['num_rev_tl_bal_gt_0'].mean()), inplace=True)\n",
    "trainData1['num_tl_120dpd_2m'].fillna((trainData1['num_sats'].mean()), inplace=True)\n",
    "trainData1['num_tl_30dpd'].fillna((trainData1['num_tl_30dpd'].mean()), inplace=True)\n",
    "trainData1['num_tl_90g_dpd_24m'].fillna((trainData1['num_tl_90g_dpd_24m'].mean()), inplace=True)\n",
    "trainData1['num_tl_op_past_12m'].fillna((trainData1['num_tl_op_past_12m'].mean()), inplace=True)\n",
    "trainData1['pct_tl_nvr_dlq'].fillna((trainData1['pct_tl_nvr_dlq'].mean()), inplace=True)\n",
    "trainData1['percent_bc_gt_75'].fillna((trainData1['percent_bc_gt_75'].mean()), inplace=True)\n",
    "trainData1['pub_rec_bankruptcies'].fillna((trainData1['pub_rec_bankruptcies'].mean()), inplace=True)\n",
    "trainData1['tax_liens'].fillna((trainData1['tax_liens'].mean()), inplace=True)\n",
    "trainData1['tot_hi_cred_lim'].fillna((trainData1['tot_hi_cred_lim'].mean()), inplace=True)\n",
    "trainData1['total_bal_ex_mort'].fillna((trainData1['total_bal_ex_mort'].mean()), inplace=True)\n",
    "trainData1['total_il_high_credit_limit'].fillna((trainData1['total_il_high_credit_limit'].mean()), inplace=True)\n",
    "\n",
    "\n",
    "trainData1['revol_util'].fillna((trainData1['revol_util'].median()), inplace=True)\n",
    "trainData1['collections_12_mths_ex_med'].fillna((trainData1['collections_12_mths_ex_med'].median()), inplace=True)\n",
    "trainData1['acc_open_past_24mths'].fillna((trainData1['acc_open_past_24mths'].median()), inplace=True)\n",
    "trainData1['avg_cur_bal'].fillna((trainData1['avg_cur_bal'].median()), inplace=True)\n",
    "trainData1['bc_open_to_buy'].fillna((trainData1['bc_open_to_buy'].median()), inplace=True)\n",
    "trainData1['bc_util'].fillna((trainData1['bc_util'].median()), inplace=True)\n",
    "trainData1['chargeoff_within_12_mths'].fillna((trainData1['chargeoff_within_12_mths'].median()), inplace=True)\n",
    "trainData1['mo_sin_old_rev_tl_op'].fillna((trainData1['mo_sin_old_rev_tl_op'].median()), inplace=True)\n",
    "trainData1['mo_sin_rcnt_rev_tl_op'].fillna((trainData1['mo_sin_rcnt_rev_tl_op'].median()), inplace=True)\n",
    "trainData1['mo_sin_rcnt_tl'].fillna((trainData1['mo_sin_rcnt_tl'].median()), inplace=True)\n",
    "trainData1['mort_acc'].fillna((trainData1['mort_acc'].median()), inplace=True)\n",
    "trainData1['mths_since_recent_bc'].fillna((trainData1['mths_since_recent_bc'].median()), inplace=True)\n",
    "trainData1['mths_since_recent_inq'].fillna((trainData1['mths_since_recent_inq'].median()), inplace=True)\n",
    "trainData1['num_sats'].fillna((trainData1['num_sats'].median()), inplace=True)\n",
    "trainData1['inq_last_6mths'].fillna((trainData1['inq_last_6mths'].median()), inplace=True)\n",
    "trainData1['delinq_amnt'].fillna((trainData1['delinq_amnt'].median()), inplace=True)\n",
    "trainData1['loan_status'].fillna((trainData1['loan_status'].median()), inplace=True)\n",
    "\n",
    "\n",
    "x = pd.concat([numerical_columns, trainData['application_type'], trainData['term'], dummy_df, trainData1], axis = 1).astype(float)\n",
    "df = pd.DataFrame(x)\n",
    "df = df.dropna(axis=0, subset=['loan_status'])\n",
    "x = df.dropna(axis='columns')\n",
    "print(x.columns)\n",
    "train_cols = x.columns\n",
    "df = pd.DataFrame({'n': x.columns})\n",
    "import csv\n",
    "with open('trainn.csv', 'w', newline='') as file:\n",
    "     df.to_csv(file,index=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bEjHwBe7ketT"
   },
   "source": [
    "**TESTING SET PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bDMupmdaruBn",
    "outputId": "3cf1f377-82a7-4594-e754-41ba444a3710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303605, 129)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numvars_2_t = ['loan_amnt','revol_bal']\n",
    "numerical_columns_t = pd.DataFrame(StandardScaler().fit_transform(testData[numvars_2_t]),columns = numvars_2_t)\n",
    "\n",
    "#Binary\n",
    "testData['application_type'] = pd.to_numeric(testData['application_type'], errors='coerce')\n",
    "testData['emp_length'] = pd.to_numeric(testData['emp_length'], errors='coerce')\n",
    "testData['earliest_cr_line'] = pd.to_numeric(testData['earliest_cr_line'], errors='coerce')\n",
    "LE_t = LabelEncoder()\n",
    "testData['application_type'] = LE_t.fit_transform(testData['application_type'])\n",
    "testData['term'] = LE_t.fit_transform(testData['term'].astype(str))\n",
    "#categorical variables labels\n",
    "\n",
    "categorical_t = ['grade', 'emp_length','home_ownership','verification_status', 'purpose', 'addr_state', 'earliest_cr_line']\n",
    "dummy_df_t = pd.get_dummies(testData[categorical_t])\n",
    "dummy_df_t = dummy_df_t.drop('emp_length', axis =1)\n",
    "dummy_df_t = dummy_df_t.drop('earliest_cr_line', axis =1)\n",
    "testData1 = testData.drop('application_type',axis=1)\n",
    "testData1 = testData1.drop('term',axis=1)\n",
    "testData1 = testData1.drop('ID',axis=1)\n",
    "testData1 = testData1.drop(categorical_t, axis=1)\n",
    "testData1 = testData1.drop('zip_code', axis = 1)\n",
    "testData1 = testData1.drop('emp_title', axis=1)\n",
    "testData1 = testData1.drop(numvars_2_t, axis=1)\n",
    "\n",
    "testData1['tot_coll_amt'].fillna((trainData1['tot_coll_amt'].mean()), inplace=True)\n",
    "testData1['tot_cur_bal'].fillna((trainData1['tot_cur_bal'].mean()), inplace=True)\n",
    "testData1['total_rev_hi_lim'].fillna((trainData1['total_rev_hi_lim'].mean()), inplace=True)\n",
    "testData1['num_accts_ever_120_pd'].fillna((trainData1['num_accts_ever_120_pd'].mean()), inplace=True)\n",
    "testData1['dti'].fillna((trainData1['dti'].mean()), inplace=True)\n",
    "testData1['delinq_2yrs'].fillna((trainData1['delinq_2yrs'].mean()), inplace=True)\n",
    "testData1['num_actv_bc_tl'].fillna((trainData1['num_actv_bc_tl'].mean()), inplace=True)\n",
    "testData1['num_actv_rev_tl'].fillna((trainData1['num_actv_rev_tl'].mean()), inplace=True)\n",
    "testData1['num_bc_sats'].fillna((trainData1['num_bc_sats'].mean()), inplace=True)\n",
    "testData1['num_bc_tl'].fillna((trainData1['num_bc_tl'].mean()), inplace=True)\n",
    "testData1['num_il_tl'].fillna((trainData1['num_il_tl'].mean()), inplace=True)\n",
    "testData1['num_op_rev_tl'].fillna((trainData1['num_op_rev_tl'].mean()), inplace=True)\n",
    "testData1['num_rev_accts'].fillna((trainData1['num_rev_accts'].mean()), inplace=True)\n",
    "testData1['num_rev_tl_bal_gt_0'].fillna((trainData1['num_rev_tl_bal_gt_0'].mean()), inplace=True)\n",
    "testData1['num_tl_120dpd_2m'].fillna((trainData1['num_sats'].mean()), inplace=True)\n",
    "testData1['num_tl_30dpd'].fillna((trainData1['num_tl_30dpd'].mean()), inplace=True)\n",
    "testData1['num_tl_90g_dpd_24m'].fillna((trainData1['num_tl_90g_dpd_24m'].mean()), inplace=True)\n",
    "testData1['num_tl_op_past_12m'].fillna((trainData1['num_tl_op_past_12m'].mean()), inplace=True)\n",
    "testData1['pct_tl_nvr_dlq'].fillna((trainData1['pct_tl_nvr_dlq'].mean()), inplace=True)\n",
    "testData1['percent_bc_gt_75'].fillna((trainData1['percent_bc_gt_75'].mean()), inplace=True)\n",
    "testData1['pub_rec_bankruptcies'].fillna((trainData1['pub_rec_bankruptcies'].mean()), inplace=True)\n",
    "testData1['tax_liens'].fillna((trainData1['tax_liens'].mean()), inplace=True)\n",
    "testData1['tot_hi_cred_lim'].fillna((trainData1['tot_hi_cred_lim'].mean()), inplace=True)\n",
    "testData1['total_bal_ex_mort'].fillna((trainData1['total_bal_ex_mort'].mean()), inplace=True)\n",
    "testData1['total_il_high_credit_limit'].fillna((trainData1['total_il_high_credit_limit'].mean()), inplace=True)\n",
    "\n",
    "\n",
    "testData1['revol_util'].fillna((trainData1['revol_util'].median()), inplace=True)\n",
    "testData1['collections_12_mths_ex_med'].fillna((trainData1['collections_12_mths_ex_med'].median()), inplace=True)\n",
    "testData1['acc_open_past_24mths'].fillna((trainData1['acc_open_past_24mths'].median()), inplace=True)\n",
    "testData1['avg_cur_bal'].fillna((trainData1['avg_cur_bal'].median()), inplace=True)\n",
    "testData1['bc_open_to_buy'].fillna((trainData1['bc_open_to_buy'].median()), inplace=True)\n",
    "testData1['bc_util'].fillna((trainData1['bc_util'].median()), inplace=True)\n",
    "testData1['chargeoff_within_12_mths'].fillna((trainData1['chargeoff_within_12_mths'].median()), inplace=True)\n",
    "testData1['mo_sin_old_rev_tl_op'].fillna((trainData1['mo_sin_old_rev_tl_op'].median()), inplace=True)\n",
    "testData1['mo_sin_rcnt_rev_tl_op'].fillna((trainData1['mo_sin_rcnt_rev_tl_op'].median()), inplace=True)\n",
    "testData1['mo_sin_rcnt_tl'].fillna((trainData1['mo_sin_rcnt_tl'].median()), inplace=True)\n",
    "testData1['mort_acc'].fillna((trainData1['mort_acc'].median()), inplace=True)\n",
    "testData1['mths_since_recent_bc'].fillna((trainData1['mths_since_recent_bc'].median()), inplace=True)\n",
    "testData1['mths_since_recent_inq'].fillna((trainData1['mths_since_recent_inq'].median()), inplace=True)\n",
    "testData1['num_sats'].fillna((trainData1['num_sats'].median()), inplace=True)\n",
    "testData1['inq_last_6mths'].fillna((trainData1['inq_last_6mths'].median()), inplace=True)\n",
    "testData1['delinq_amnt'].fillna((trainData1['delinq_amnt'].median()), inplace=True)\n",
    "\n",
    "\n",
    "x_test = pd.concat([numerical_columns_t, testData['application_type'], testData['term'], dummy_df_t, testData1], axis = 1).astype(float)\n",
    "\n",
    "test_cols = x_test.columns\n",
    "\n",
    "for c_col in test_cols:\n",
    "  if c_col not in train_cols:\n",
    "    x_test = x_test.drop(c_col, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "print(x_test.shape)\n",
    "df = pd.DataFrame({'n': x_test.columns})\n",
    "import csv\n",
    "with open('testt.csv', 'w', newline='') as file:\n",
    "     df.to_csv(file,index=True)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwdSFhD2Qcc1"
   },
   "source": [
    "# Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Cv9EeN84Qb1t",
    "outputId": "6dd24975-57ee-40cc-ec54-af0009c81659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    799440\n",
      "0.0    200560\n",
      "Name: loan_status, dtype: int64\n",
      "1.0    799440\n",
      "0.0    200560\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = x['loan_status']\n",
    "\n",
    "# Check the value_count of classification attribute\n",
    "# 1 = 'good' credit, 2 = 'bad' credit\n",
    "print(y.value_counts())\n",
    "\n",
    "# Binarize the y output for easier use \n",
    "y.replace([1,2], [1,0], inplace=True)\n",
    "\n",
    "# Print again\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xb071uGc2_TK",
    "outputId": "e1590b88-9e69-4675-afb0-42c9a94e19d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 129)\n",
      "(303605, 129)\n"
     ]
    }
   ],
   "source": [
    "for b_col in train_cols:\n",
    "  if b_col not in test_cols:\n",
    "    x = x.drop(b_col, axis = 1)\n",
    "print(x.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFNpNnyrZCwk"
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from numpy import set_printoptions\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectFpr\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "\n",
    "test = SelectKBest(score_func=f_classif, k=48)\n",
    "#test = SelectFpr(f_classif, alpha=0.1)\n",
    "fitt = test.fit(x, y)\n",
    "set_printoptions(precision=5)\n",
    "#print(fit.scores_)\n",
    "x = fitt.transform(x)\n",
    "x_test = fitt.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6ZOYdgAWyPy"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = stats.zscore(x)\n",
    "x_test = stats.zscore(x_test)\n",
    "x = preprocessing.scale(x)\n",
    "x_test = preprocessing.scale(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZFDXwseSPKm"
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.30)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in skf.split(x, y):  #train and test indexes 4th\n",
    "    X_train, X_valid = x[train_index], x[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CNibVNUkTQ9t"
   },
   "source": [
    "# Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaJM8Vdqmt6S"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import fbeta_score\n",
    "def evaluateModel(X_train, y_train,X_valid,y_valid,classifiers):\n",
    "    for clf in classifiers:\n",
    "        print(clf)\n",
    "        clf.fit(X_train, y_train)\n",
    "        test_pred = clf.predict(X_valid)\n",
    "        true_positive_m = (test_pred == 1) & (y_valid == 1)\n",
    "        true_positive = len(test_pred[true_positive_m])\n",
    "        print('True Positive = ' + str(true_positive))\n",
    "\n",
    "        false_positive_m = (test_pred == 1) & (y_valid == 0)\n",
    "        false_positive = len(test_pred[false_positive_m])\n",
    "        print('False Positive = ' + str(false_positive))\n",
    "\n",
    "        true_negative_m = (test_pred == 0) & (y_valid == 0)\n",
    "        true_negative = len(test_pred[true_negative_m])\n",
    "        print('True Negative = ' + str(true_negative))\n",
    "\n",
    "        precision = (true_positive)/(true_positive + false_positive)\n",
    "        print('Precision = ' + str(precision))\n",
    "        print('Average precision = ' + str(metrics.average_precision_score(y_valid, test_pred)))\n",
    "        print('F-beta Score = ' + str(metrics.fbeta_score(y_valid, test_pred, average='macro', beta=0.5)))\n",
    "        print(\"-----------------------\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "XjKMhCg4Lfsb",
    "outputId": "9406e7fc-4b48-4b90-8425-f80bdba73b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-beta Score = 0.6109565496414908\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "True Positive = 62476\n",
      "False Positive = 10624\n",
      "True Negative = 9432\n",
      "Precision = 0.8546648426812585\n",
      "Average precision = 0.8425980515279985\n",
      "F-beta Score = 0.6041928593247328\n",
      "-----------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "gaussian_nb=GaussianNB()\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "lg = LogisticRegression(random_state=0)\n",
    "mlp = MLPClassifier(solver='lbfgs', max_iter=500)\n",
    "\n",
    "#chosen classifier\n",
    "clf = BaggingClassifier(base_estimator=GaussianNB(), n_estimators=17 , random_state=0, max_features = 0.65).fit(X_train, y_train)\n",
    "tpred = clf.predict(X_valid)\n",
    "print('F-beta Score = ' + str(metrics.fbeta_score(y_valid, tpred, average='macro', beta=0.5)))\n",
    "\n",
    "\n",
    "classifiers = [gaussian_nb]\n",
    "print(evaluateModel(X_train, y_train,X_valid,y_valid,classifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLQMpo5GcDGk"
   },
   "source": [
    "**ACTUAL TEST SET PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ydue8xrkaeUy",
    "outputId": "d43b4d47-976e-46c8-e276-5d149bead3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303605, 48)\n"
     ]
    }
   ],
   "source": [
    "X_train = x\n",
    "y_train = y\n",
    "X_test = x_test\n",
    "y_test = []\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "POuu0qnpaUlL",
    "outputId": "d2f23c9e-4ef2-400d-8846-7b0480ac158c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#clf = GaussianNB().fit(X_train, y_train)\n",
    "clf = BaggingClassifier(base_estimator=GaussianNB(), n_estimators=17 , random_state=0, max_features = 0.65).fit(X_train, y_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "print(test_pred) \n",
    "\n",
    "# TEST PRED IS THE FILE THAT WE WILL SUBMIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X6Wb5mMmqGhS",
    "outputId": "683346d9-d203-4036-8281-a538813f1fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ms6QMMoemt6f"
   },
   "outputs": [],
   "source": [
    "#create a data frame to create the csv file consisting of predictions\n",
    "ID = np.arange(0,303605)\n",
    "df = pd.DataFrame({'loan_status': test_pred.astype(int)})\n",
    "df.index.name = 'ID'\n",
    "import csv\n",
    "with open('loan_statusGS.csv', 'w', newline='') as file:\n",
    "     df.to_csv(file,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lULlwYJAmt6h",
    "outputId": "7a965362-ae60-466a-ba47-88ca32e0f210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "test_pred = dt.predict(X_test)\n",
    "ID = np.arange(0,303605)\n",
    "#create a data frame to create the csv file consisting of predictions\n",
    "df = pd.DataFrame({'loan_status': test_pred})\n",
    "import csv\n",
    "with open('loan_statusDT.csv', 'w', newline='') as file:\n",
    "     df.to_csv(file,index=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oH3ghgeAmt6k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "412_PROJECT_(5) (2).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
